从攻略文档（doclist）中提取游戏名称的脚本

## 版本

##### 第一版：基础功能

1. 能够跑出文档中出现频率最高的字（top N 个），实现方法是用一个 list 存字，一个 list 存字的出现次数。
2. 跑出特定字（或词，称为 A）的下一个字的出现频率，取 top1（称为 B）进行组词，根据P（B|A）：P（A）来判断 AB 是否是一个词。

##### 第二版： list → dict

1. 按照熊哥的模板，将 list 改成 dict，找文章中的 topn 个关键词，时间从4秒缩短到18毫秒（内容 = 5000行*20字）
2. 递归 bug 暴露：递归条件 = P（B|A）/P(A) > 0.7，这里并没有考虑到 P（A） == 1时将无限递归，暂时修改成了递归条件 = （P（B|A）-1）/P(A) > 0.7

##### 第三版：使用相对路径

1. 使用相对路径。
2. 因为游戏名经常出现在行首，因此尝试在找 topn 的字时增加前几个字的权重，发现这样会导致组词失败（因为 P（A）大幅提升，导致 AB 组词难度提升）。

##### 第四版：修改找跟随字的策略

1. 旧方法：读取全文 → 找到第一个当前字 → 从当前字位置截断，阶段后的第一个字是跟随字，之后是新的全文并再次迭代。
2. 新方法：读取全文 → 全文按照当前字分段成为 list → 每个元素都取第一个字。
		> 现在有瑕疵就是分割之后的第一段，部分需要删掉。
	+ 时间收益：

	次数 | 第一次 | 第二次 | 第三次 | 第四次 | 第五次 | 均值
	---- | ---- | ---- |---- | ---- | ----|----
	新时间 | 4.86 | 4.87 | 5.06 | 5.08 | 4.96 | 4.97
	原时间 | 6.26 | 7.10 | 6.58 | 6.49 | 6.39 | 6.56
3. 尝试用 Counter()替换熊哥教的 Dict，结果效率反而变差了。

##### 第五版：双向匹配

1. 组词时增加前向匹配，经过试验先前向匹配，再后向匹配，质量会稍好一些。

##### 第六版：多一层组词

1. 在组词时，将 topn 的跟随字全部拿出来组词（第二版中的 B 只是 A 的 top1跟随字，现在将会跑所有跟随字），同时修改了：
  + 比如天天（出现了1000次）字后面出现次数最高的两个字分别是炫（300）、酷（100次），那么在判断天天炫是一个词之后，会把天天的出现次数减去300，也就是判断天天炫是否是一个词时分母只有700。

##### 第七版：完全重写

1. 通过错位相加，把文章中的 n字对 全部找出来。

2. 然后根据 n字对 的长短，从最长的 n字对 开始，明确 n字对 的出现次数，然后：

3. 第一步：判断被 n字对 包含的词是否不是词：

   + 将 n字对 的所有子对都列出来。

   - 假如 p(n字对|子对）< 0.5 => 子对不是词。

4. 第二步：判断 n字对 是否是由多个词组成的

   + 将 n字对 拆分成任意两段（分别叫 Ai 和 Bi），取这两段的出现次数的最低值（最不像词）。

   - 计算 α = p(n字对) / max(min(Ai,Bi) for I in range(len(n字对)-1)
   - 假如 α 太小，说明 n字对 可能是由多个词组成（但是不能解决这个 n字对 由 3 个词组成的情况）
   - 这个算法有两个问题：
   - 一是：α 没有概率学上的含义。
   - 二是有反例：志明和春娇 是由三个词组成，但是志明和不是词，所以会计算 p(志明和春娇) / min(p(志明和),p(春娇)) 会被误导；但是又不能拆分成单字，否则 p(志明和春娇) / min(p(志),p(明),p(和),p(春),p(娇)) 也不能构成任何问题。除非已经明确了志明是词、春娇是词，和是词，这时候才能否定志明和春娇。